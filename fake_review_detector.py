# -*- coding: utf-8 -*-
"""fake_review_detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VXBhqeGQsbBmc270iwNJv46fZZFPlYqA
"""

import pandas as pd

# Load the dataset
data = pd.read_csv("fake_reviews.csv")  # Change to your actual file name

# Show the first 5 rows
print("First 5 rows of the dataset:")
print(data.head())

# Check dataset details
print("\nDataset Info:")
print(data.info())

!pip install pandas numpy nltk scikit-learn matplotlib seaborn

import pandas as pd

# Load the dataset (Make sure your dataset file is uploaded in Colab)
data = pd.read_csv("fake_reviews.csv")  # Replace with your dataset filename

# Show the first 5 rows
print("First 5 rows of the dataset:")
print(data.head())

# Check dataset details
print("\nDataset Info:")
print(data.info())

# Show column names
print("\nColumn Names:")
print(data.columns)

import nltk
nltk.download('punkt')

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Download necessary resources
nltk.download('stopwords')
nltk.download('punkt')
# Download the 'punkt_tab' resource
nltk.download('punkt_tab') # This line is added

# Function to clean text data
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    words = word_tokenize(text)  # Tokenize words
    words = [word for word in words if word not in stopwords.words('english')]  # Remove stopwords
    return ' '.join(words)

# Apply cleaning function to the text column
data['cleaned_text'] = data['text'].apply(clean_text)

# Show cleaned text
print(data[['text', 'cleaned_text']].head())

print("Column Names in Dataset:", data.columns)

from sklearn.feature_extraction.text import TfidfVectorizer

# Convert text into numerical form using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)  # Use top 5000 words
X = vectorizer.fit_transform(data['cleaned_text'])  # Make sure 'cleaned_text' column exists

# Show the shape of the transformed data
print("Shape of transformed data:", X.shape)

# Create a label column (1 = Fake, 0 = Real) based on star ratings
data['label'] = data['stars'].apply(lambda x: 1 if x <= 3 else 0)

# Show the count of real vs fake reviews
print(data['label'].value_counts())

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Split the dataset into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, data['label'], test_size=0.2, random_state=42)

# Train the NaÃ¯ve Bayes model
model = MultinomialNB()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Check accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")

# Show detailed performance report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

def predict_fake_review(review):
    # Preprocess the new review
    review_cleaned = clean_text(review)  # Apply the same cleaning function
    review_vectorized = vectorizer.transform([review_cleaned])  # Convert to numerical form

    # Predict
    prediction = model.predict(review_vectorized)[0]

    # Return result
    return "Fake Review ðŸ˜¡" if prediction == 1 else "Real Review âœ…"

# Example reviews for testing
test_reviews = [
    "This product is amazing! I love it so much!",
    "Worst purchase ever. Total waste of money.",
    "The service was good, but the quality could be better.",
    "I got paid to write this review. LOL.",
    "Absolutely terrible, do not buy this!"
]

# Predict and display results
for review in test_reviews:
    print(f"Review: {review}")
    print(f"Prediction: {predict_fake_review(review)}\n")

from imblearn.over_sampling import SMOTE
from collections import Counter

# Apply SMOTE to balance the dataset
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, data['label'])

# Check new dataset balance
print("Before SMOTE:", Counter(data['label']))
print("After SMOTE:", Counter(y_resampled))


from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# Split the balanced dataset
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Train the Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Check accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"New Model Accuracy: {accuracy:.2f}")

# Show detailed performance report
print("\nUpdated Classification Report:")
print(classification_report(y_test, y_pred))

def predict_fake_review(review):
    # Preprocess the new review
    review_cleaned = clean_text(review)  # Apply the same cleaning function
    review_vectorized = vectorizer.transform([review_cleaned])  # Convert to numerical form

    # Predict using the improved model
    prediction = model.predict(review_vectorized)[0]

    # Return result
    return "Fake Review ðŸ˜¡" if prediction == 1 else "Real Review âœ…"

# Example reviews for testing
test_reviews = [
    "This product is amazing! I love it so much!",
    "Worst purchase ever. Total waste of money.",
    "The service was good, but the quality could be better.",
    "I got paid to write this review. LOL.",
    "Absolutely terrible, do not buy this!"
]

# Predict and display results
for review in test_reviews:
    print(f"Review: {review}")
    print(f"Prediction: {predict_fake_review(review)}\n")

import joblib

# Save the model
joblib.dump(model, "fake_review_detector.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("âœ… Model and vectorizer saved successfully!")

from google.colab import files

# Download both files
files.download("fake_review_detector.pkl")
files.download("tfidf_vectorizer.pkl")

import joblib

# Load the saved model and vectorizer
model = joblib.load("fake_review_detector.pkl")
vectorizer = joblib.load("tfidf_vectorizer.pkl")

# Function to predict a new review
def predict_fake_review(review):
    review_cleaned = clean_text(review)  # Apply the same cleaning function
    review_vectorized = vectorizer.transform([review_cleaned])  # Convert to numerical form
    prediction = model.predict(review_vectorized)[0]
    return "Fake Review ðŸ˜¡" if prediction == 1 else "Real Review âœ…"

# Example test
new_review = "This is the worst product ever, don't buy it!"
print(f"Review: {new_review}\nPrediction: {predict_fake_review(new_review)}")

import pandas as pd

# Create a small sample dataset
data = {
    "text": [
        "This product is amazing! I love it.",
        "Worst purchase ever, don't buy!",
        "Great quality, very satisfied.",
        "This is a scam, fake reviews everywhere.",
        "Fast shipping and excellent customer service."
    ],
    "label": [0, 1, 0, 1, 0]  # 0 = Real, 1 = Fake
}

# Convert to DataFrame
df = pd.DataFrame(data)

# Save to CSV file
df.to_csv("fake_reviews.csv", index=False)

print("Dataset created successfully!")

import os
print(os.listdir())  # This will list all files in the current directory

import pandas as pd

# Load the dataset
data = pd.read_csv("fake_reviews.csv")  # Ensure the file name matches exactly

# Display the first few rows
print(data.head())  # Check if the data is loaded correctly

import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Convert text to numerical data
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data["text"])  # Change "text" if your column name is different
y = data["label"]  # Change "label" if your column name is different

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Random Forest model
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# Train the SVM model
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)

# Save the trained models
joblib.dump(rf_model, "random_forest_model.pkl")
joblib.dump(svm_model, "svm_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("Models trained and saved successfully!")

import os
print(os.listdir())  # This will show all files in the current directory

from google.colab import files

files.download("random_forest_model.pkl")
files.download("svm_model.pkl")
files.download("tfidf_vectorizer.pkl")

import joblib
import os

# Create a folder for models if it doesn't exist
model_dir = "models"
if not os.path.exists(model_dir):
    os.makedirs(model_dir)

# Save models in the 'models' directory
joblib.dump(rf_model, os.path.join(model_dir, "random_forest_model.pkl"))
joblib.dump(svm_model, os.path.join(model_dir, "svm_model.pkl"))
joblib.dump(vectorizer, os.path.join(model_dir, "tfidf_vectorizer.pkl"))

print("Models saved successfully in the 'models' folder!")

import joblib
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Load dataset
data = pd.read_csv("fake_reviews.csv")  # Make sure this file exists!

# Vectorization (This step is CRUCIAL!)
vectorizer = TfidfVectorizer(max_features=5000)  # Make sure all models use the same features
X = vectorizer.fit_transform(data["text"])  # Replace "text" with your actual column name
y = data["label"]  # Replace "label" with your actual column name

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# Train SVM model
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)

# Save models and vectorizer
joblib.dump(rf_model, "random_forest_model.pkl")
joblib.dump(svm_model, "svm_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("âœ… Models and vectorizer saved successfully!")

from google.colab import files

files.download("random_forest_model.pkl")
files.download("svm_model.pkl")
files.download("tfidf_vectorizer.pkl")

import joblib
import os

# Create a folder for models if it doesn't exist
model_dir = "models"
if not os.path.exists(model_dir):
    os.makedirs(model_dir)

# Save models in the 'models' directory
joblib.dump(rf_model, os.path.join(model_dir, "random_forest_model.pkl"))
joblib.dump(svm_model, os.path.join(model_dir, "svm_model.pkl"))
joblib.dump(vectorizer, os.path.join(model_dir, "tfidf_vectorizer.pkl"))

print("Models saved successfully in the 'models' folder!")

import joblib
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Load dataset
data = pd.read_csv("fake_reviews.csv")  # Ensure this file is present in your working directory

# Use the same vectorizer for training & prediction
vectorizer = TfidfVectorizer(max_features=25)  # Ensure models & app use the same number of features
X = vectorizer.fit_transform(data["text"])  # Ensure "text" column is correct
y = data["label"]  # Ensure "label" column is correct (0 for real, 1 for fake)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# Train SVM model
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)

# Save models and vectorizer
joblib.dump(rf_model, "random_forest_model.pkl")
joblib.dump(svm_model, "svm_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("âœ… Models and vectorizer saved successfully with 25 features!")

from google.colab import files

files.download("random_forest_model.pkl")
files.download("svm_model.pkl")
files.download("tfidf_vectorizer.pkl")

import joblib
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# Load dataset
data = pd.read_csv("fake_reviews.csv")  # Ensure this file exists

# Create and fit TF-IDF vectorizer
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(data["text"])  # Ensure "text" column is correct

# Save the vectorizer
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("âœ… tfidf_vectorizer.pkl created successfully!")

from google.colab import files

files.download("random_forest_model.pkl")
files.download("svm_model.pkl")
files.download("tfidf_vectorizer.pkl")

from google.colab import files
files.download("tfidf_vectorizer.pkl")

pip install streamlit joblib nltk matplotlib requests streamlit-lottie

from google.colab import files

files.download("fake_review_detector.pkl")  # Download model
files.download("tfidf_vectorizer.pkl")  # Download vectorizer
files.download("random_forest_model.pkl")  # If using Random Forest
files.download("svm_model.pkl")  # If using SVM

!ls -lh

!ls -lh models/

!find / -name "fake_review_detector.pkl" 2>/dev/null

files.download("/content/models/fake_review_detector.pkl")

import joblib
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Load dataset
data = pd.read_csv("fake_reviews.csv")  # Make sure this file exists

# Preprocessing
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(data["text"]).toarray()
y = data["label"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train models
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)

# Save models
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")
joblib.dump(rf_model, "random_forest_model.pkl")
joblib.dump(svm_model, "svm_model.pkl")
joblib.dump(rf_model, "fake_review_detector.pkl")  # Default model
print("âœ… Models trained and saved successfully!")

from google.colab import files

files.download("fake_review_detector.pkl")
files.download("tfidf_vectorizer.pkl")
files.download("random_forest_model.pkl")
files.download("svm_model.pkl")

import pandas as pd
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Load dataset
data = pd.read_csv("fake_reviews.csv")  # Ensure this file is in your directory

# Use the correct column containing reviews
X = data["text"]  # Adjust this based on your dataset's column name
y = data["label"]  # Ensure the label column is correct

# Vectorize text
vectorizer = TfidfVectorizer(max_features=5000)
X_transformed = vectorizer.fit_transform(X)

# Save the vectorizer
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)

# Train RandomForest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
joblib.dump(rf_model, "random_forest_model.pkl")

# Train SVM
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)
joblib.dump(svm_model, "svm_model.pkl")

print("Models trained and saved successfully!")

from google.colab import files
uploaded = files.upload()

import os
print(os.listdir())  # This will list all files in the current directory

import pandas as pd

# Load the dataset
data = pd.read_csv("fake_reviews.csv")

# Display the first 5 rows to check if it loaded correctly
print(data.head())

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import joblib

# Ensure the correct column name
print(data.columns)  # Check available column names

# Use the correct column name containing reviews
X = data["text"]  # Change "text" to the actual column name
y = data["label"]  # Ensure the correct label column

# Convert text to TF-IDF vectors
vectorizer = TfidfVectorizer(max_features=5000)
X_transformed = vectorizer.fit_transform(X)

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)

# Train & save Random Forest Model
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
joblib.dump(rf_model, "random_forest_model.pkl")  # Save the model

# Train & save SVM Model
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)
joblib.dump(svm_model, "svm_model.pkl")  # Save the model

# Save vectorizer
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id', 'cool', 'useful', 'funny']

X = data["text"]  # The review text
y = data["stars"]  # The rating as a label

from google.colab import files

files.download("fake_review_detector.pkl")  # Download the model
files.download("tfidf_vectorizer.pkl")  # Download the vectorizer
files.download("random_forest_model.pkl")  # If using Random Forest
files.download("svm_model.pkl")  # If using SVM

import pandas as pd
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

# âœ… Load Dataset
df = pd.read_csv("fake_reviews.csv")  # Ensure this file is in your Colab session

# âœ… Use the Correct Column Name (Check your dataset columns!)
df = df[['text', 'stars']]  # Assuming 'text' contains reviews & 'stars' is the label
df['label'] = df['stars'].apply(lambda x: 1 if x <= 2 else 0)  # Convert stars to Fake(1) / Real(0)

# âœ… Split Data
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)

# âœ… TF-IDF Vectorization (Make sure it's saved & used for all models!)
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# âœ… Train & Save Models (Ensuring they match the vectorizer)
log_reg = LogisticRegression()
log_reg.fit(X_train_tfidf, y_train)
joblib.dump(log_reg, "fake_review_detector.pkl")  # Save Logistic Regression Model

random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train_tfidf, y_train)
joblib.dump(random_forest, "random_forest_model.pkl")  # Save Random Forest Model

svm = SVC(probability=True)
svm.fit(X_train_tfidf, y_train)
joblib.dump(svm, "svm_model.pkl")  # Save SVM Model

# âœ… Save TF-IDF Vectorizer
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("âœ… Models and vectorizer trained & saved successfully!")

import pandas as pd
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

# âœ… Load the dataset
df = pd.read_csv("fake_reviews.csv")  # Ensure this file is in your Colab session

# âœ… Use the correct column name (Check your dataset columns!)
df = df[['text', 'stars']]  # Ensure 'text' contains reviews & 'stars' is the label
df['label'] = df['stars'].apply(lambda x: 1 if x <= 2 else 0)  # Convert stars to Fake(1) / Real(0)

# âœ… Split Data
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)

# âœ… TF-IDF Vectorization (Make sure it's saved & used for all models!)
vectorizer = TfidfVectorizer(max_features=5000)  # Ensure this number matches training and testing
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# âœ… Train & Save Models
log_reg = LogisticRegression()
log_reg.fit(X_train_tfidf, y_train)
joblib.dump(log_reg, "fake_review_detector.pkl")  # Save Logistic Regression Model

random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train_tfidf, y_train)
joblib.dump(random_forest, "random_forest_model.pkl")  # Save Random Forest Model

svm = SVC(probability=True)
svm.fit(X_train_tfidf, y_train)
joblib.dump(svm, "svm_model.pkl")  # Save SVM Model

# âœ… Save TF-IDF Vectorizer
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

print("âœ… Models and vectorizer trained & saved successfully!")

from google.colab import files

files.download("fake_review_detector.pkl")
files.download("random_forest_model.pkl")
files.download("svm_model.pkl")
files.download("tfidf_vectorizer.pkl")

from google.colab import files

# Download trained models
files.download("fake_review_detector.pkl")  # Logistic Regression Model
files.download("random_forest_model.pkl")  # Random Forest Model
files.download("svm_model.pkl")  # SVM Model

# Download vectorizer
files.download("tfidf_vectorizer.pkl")  # TF-IDF Vectorizer